---
title: "PML-Project: Classification based on a set of variables to predict the manner in which the excersie is done"
author: "Mahmood Karimi"
date: "27 Aug 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive summary
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 
Based on these data we are going to build a prediction model, which predicts the manner in which the excersize is done according to quantified variables.

## Data and environment preparation
In this section we are going to do the following tasks:

* load needed libraries
* load the training and test data sets
* Remove unneeded variables which does not have correct effect of prediction such as timestamp,...
* Remove variables which contrain NA values
```{r warning=FALSE, message=FALSE}
library(caret)
library(ggplot2)
library(randomForest)
library(corrplot)
library(rpart)
set.seed(1000)

mainDir <- getwd()
subDir <- "outputDirectory"
if (!file.exists(subDir)){
        dir.create(file.path(mainDir, subDir))
}

if(!file.exists("outputDirectory/training.csv")){
        fileURL_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
        download.file(fileURL_train, destfile = "outputDirectory/training.csv")
        
}

if(!file.exists("outputDirectory/test.csv")){
        fileURL_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
        download.file(fileURL_test, destfile = "outputDirectory/test.csv")
        
}

pmltr <- read.csv("outputDirectory/training.csv", stringsAsFactors = FALSE)
pmlts <- read.csv("outputDirectory/test.csv", stringsAsFactors = FALSE)

# remove index variable which does not affect on prediction
pmltr <- pmltr[, -c(1, 3:7)]
pmltr$user_name <- as.factor(pmltr$user_name)
pmltr$classe <- as.factor(pmltr$classe)

# convert variables to number
for(i in 1:ncol(pmltr)){
        
        if(class(pmltr[,i]) == "character"){
                
                pmltr[,i] <- as.numeric(pmltr[,i])
        }
}
# remove variables which contain NA
num_na <- sapply(1:ncol(pmltr), function(x) sum(is.na(pmltr[,x])))
pmltr_new <- pmltr[, num_na == 0]
```

## Explorarory analysis
In this section we are going to do some exploratory ananlysis on training data such as: grouping data by classe and user_name variables and also draw a plot based on two variables
```{r eda}
table(pmltr_new$classe)
table(pmltr_new$user_name)
# draw some plot of data
qplot(user_name, roll_belt, colour=classe, data=pmltr_new, main = "Activity level of each user on belt", xlab = "user name", ylab = "activity level on belt")
```

## Partition training data
In this section we are going to partition training data set, to two separate chunks. The big one is dedicated for training and small one is dedicated for testing
```{r part}
inTrain <- createDataPartition(y = pmltr_new$classe, p = 0.75, list = FALSE)
tempTrain <- pmltr_new[inTrain,]
tempTest <- pmltr_new[-inTrain,]
table(tempTrain$classe)
```

## Method1: Classification Trees
In this section we build the classification Trees model based on trainings data with two fold cross validation. The result is displayed in confuction matrix and a diagram displays the importance of variables used in prediction.
```{r ct_model}
ct_model <- train(classe ~., data = tempTrain, method = "rpart", trControl=trainControl(method="cv",number=2))
confusionMatrix(predict(ct_model, newdata = tempTest), tempTest$classe)
print(plot(varImp(ct_model, scale = FALSE)))
predict(ct_model, newdata = pmlts)
```
This model has the lowest accuracy amoung the selected models and it is about 51% with confidence interval 95%.

## Method2: Gradiant Boosting Model
In this section we build the Gradiant Boosting model based on trainings data with two fold cross validation. The result is displayed in confuction matrix and a diagram displays the importance of variables used in prediction.
```{r gbm_model}
gbm_model <- train(classe ~., data = tempTrain, method = "gbm", verbose = FALSE, trControl=trainControl(method="cv",number=2))
confusionMatrix(predict(gbm_model, newdata = tempTest), tempTest$classe)
print(plot(varImp(gbm_model, scale = FALSE)))
predict(gbm_model, newdata = pmlts)
```
This model has a good accuracy and it is 96% with confidence interval 95%


## Method3: Random Forest Model
In this section we build the Random Forest model based on trainings data with two fold cross validation. The result is displayed in confuction matrix and a diagram displays the importance of variables used in prediction.
```{r rf_model}
rf_model <- train(classe ~., data = tempTrain, method = "rf", trControl=trainControl(method="cv",number=2))
confusionMatrix(predict(rf_model, newdata = tempTest), tempTest$classe)
print(plot(varImp(rf_model, scale = FALSE)))
predict(rf_model, newdata = pmlts)
```
This model has the best accuracy and it is 99% with confidence interval 95%

# End of Report

